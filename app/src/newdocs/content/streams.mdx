import cx from 'classnames'
import { Link } from 'react-router-dom'

import CodeSnippet from '$shared/components/CodeSnippet'
import Warning from '$newdocs/components/Warning'
import links from '$shared/../links'

import StreamListing from './images/streams/streamListing.png'
import StreamDetails from './images/streams/streamDetails.png'
import StreamConfigure from './images/streams/streamConfigure.png'
import StreamPreview from './images/streams/streamPreview.png'
import StreamApiAccess from './images/streams/streamApiAccess.png'
import StreamHistorical from './images/streams/streamHistorical.png'
import MessagePartitioningImage from './images/streams/message-partitioning.png'
import StreamAndPartitionsImage from './images/streams/stream-and-partitions.png'

import docsStyles from '$newdocs/components/DocsLayout/docsLayout.pcss'
import streamsStyles from '$newdocs/components/DocsPages/Streams/streamsStyles.pcss'

import {
    CreateJavascriptClient,
    CreateJavaClient,
    AuthJavascriptClient,
    AuthJavaClient,
    SubscribeJavascriptClient,
    SubscribeJavaClient,
    PublishJavascriptClient,
    PublishJavaClient,
} from './code/streams.js'

<section id="intro-to-streams">

## Intro to streams

All of the data in the Streamr network is contained inside individual streams. A stream is simply a sequence of data points in time. The data may originate, for example from machines on the factory floor, sensors in a smart city, in-house databases or systems, or from commercial streaming data feeds.

Streams have the following properties:
- Any kind of realtime data can be stored in it.
- The data will always be retrieved in the correct order.
- The data is persisted on the Streamr network and identifiable by unique ID.

Some common use cases for streams:
- Sensory readings of speed and orientation
- Geolocation
- Ambient temperature and humidity 
- Social media messages
- Stock market events
- Mobile ad impressions

These are just a few examples. There is virtually no limit on the kind, format, or quantity of data you can feed into Streamr, even digital images, streaming video, or other domain-specific data could be pushed into a stream.

Streams implement a publish-subscribe paradigm, or pub/sub for short. A stream can receive data from many sources (or publishers), and there can be several listeners who subscribe to a stream. There are several variations on the possible pub/sub topologies, such as many-to-one, one-to-many, or many-to-many. Streamr supports all of these.

If you want to try it out already, you can dive into our tutorial on <Link to={`${links.newdocs.tutorials}#building-a-simple-pub-sub-system`}>building a simple pub/sub system</Link> with Streamr.

### Example stream

Here’s an example of what a small part of a stream could look like. Each row shows one data point, and the columns correspond to the timestamp followed by two data fields, a measurement of the operating temperature and the number of rotations per minute (RPM).

| Timestamp                | Temperature   | RPM  |
| ------------------------ |:-------------:| ----:|
| 2019-08-01 11:30:01.012  | 312.56        | 3550 |
| 2019-08-01 11:30:02.239  | 312.49        | 3549 |
| 2019-08-01 11:30:04.105  | 312.42        | 3543 |
| 2016-02-01 11:30:08.122  | 313.21        | 3565 |
| 2016-02-01 11:30:11.882  | 317.45        | 3602 |

<section id ="stream-data-fields">

### Stream data fields

A field is a kind of placeholder for an individual piece of data, from a single data point. Each data point contains at least one data field, but you can have as many fields per data point as required.

For example, here's a data point in a stock market stream.

```
{
  "Symbol": "PFFT",
  "EventType": 1,
  "OrderId": 6454321,
  "Direction": "Up",
  "Trade": {"Price": 118.55, "Size": 100},
  "Ask": [
          {"Price": 118.6, "Size": 22500},
          {"Price": 118.65, "Size": 18000},
          {"Price": 118.7, "Size": 13000},
          {"Price": 118.8, "Size": 8000},
          {"Price": 119, "Size": 45000}
          ],
  "Bid": [
          {"Price": 118.5, "Size": 16500},
          {"Price": 118.45, "Size": 11000},
          {"Price": 118.4, "Size": 14200},
          {"Price": 118.2, "Size": 19000},
          {"Price": 118, "Size": 50000}
        ]
}
```

Given the structure of this data point, the stream's fields could be configured as follows:

| Field                | Field type    |
| -------------------- |:-------------:|
| Symbol               | String        |
| EventType            | Number        |
| OrderId              | Number        |
| Direction            | String        |
| Trade                | Object        |
| Ask                  | List          |
| Bid                  | List          |  

</section>

### Data field types

There’s a number of built-in data types that can be used in a stream. These are:

- **Number:** A numeric data type internally stored as a double precision (64-bit) float.
- **Boolean:** A logical data type with two possible values, True and False. In Streamr, a numeric value exactly equal to one represents logical truth. Anything else is interpreted as a logical falsehood.
- **String:** A sequence of zero or more alphabetical characters.
- **Object:** A collection of key-value pairs. Each key is a string, and the value can be of any built-in data type (even another object). Object is equivalent to Java's 'Map'.
- **List:** An ordered collection of zero or more elements. List is equivilent to an array.

Field types can be freely mixed in a single data point. And you can freely add new fields to an existing stream; you don’t have to know what fields you might eventually need. A single data point can be of any size within reason, and a stream can grow indefinitely when extended by new data points.

</section>
<section id="work-with-streams-in-core">

## Work with streams in Core
Streamr Core provides you with the tools to create, edit, share and delete your streams as well as view and inspect the streams you have purchased on the Marketplace.

### Overview of your streams
Head over to the <Link to={links.userpages.streams}>Streams page</Link> to see an overview of your subscribed streams. The list includes streams you have created and streams that you have purchased on the Marketplace.

<div className={cx(docsStyles.centered, streamsStyles.streamListing)}>
  <img src={StreamListing} />
</div>

This stream listing page gives an indication for when data was last pushed to each stream and uses traffic light indicators show the health of each stream, at a glance.

| Color        | Status                           |
| ------------ | -------------------------------- |
| Green        | Stream is receiving data         |
| Red          | Stream is not receiving data     |

Clicking on a stream will open the stream editor. You may only edit streams that you have created or have explicit permission to edit.

By clicking on the more options icon you may access advanced features for each stream, such as stream sharing and code snippets.
A new stream can be created by the clicking the **Create Stream** button.

### Editing a stream
The stream editor provides basic tools for setting up, inspecting and editing your stream. Below is a run-down of each stream editor section.

<div className={cx(docsStyles.centered, streamsStyles.streamDetails)}>
  <img src={StreamDetails} />
</div>

#### Details section
The details section provides basic information about your stream. 

- The stream name is used to identify your stream in the Core app.
- The stream description can be used to offer more information about your stream and the kind of data it contains.
- The stream ID is the unique identifier for your stream and is needed when interacting with the <Link to={links.newdocs.SDKs}>Streamr SDKs</Link>.

#### Configure section
In this section you can configure stream fields and their data types. All fields have a name and a data type.
The Autodetect feature can be used to automatically deduce fields from the stream's last received message.
It is possible to manually correct the data types if automatic detection is not suitable for your stream.

<div className={cx(docsStyles.centered, streamsStyles.streamConfigure)}>
  <img src={StreamConfigure} />
</div>

| Setting                                             | Explanation                                                                                                     |
| ----------------------------------------------------| --------------------------------------------------------------------------------------------------------------- |
| Always try to autoconfigure field names and types   | Streamr will try to automatically configure field names and types on the very first message the stream receives |
| Require all messages in this stream to be signed    | Streamr will not accept messages that are not signed                                                            |

#### Preview section
This section is used to preview data flowing into the stream. Use the live inspector to make sure your stream is receiving data and it is correctly formatted.

<div className={cx(docsStyles.centered, streamsStyles.streamPreview)}>
  <img src={StreamPreview} />
</div>

#### API Access section
Here you can manage API keys for your stream. Keys generated here grant access to only this stream and can have either read or write access.
These keys can also be removed if for example, the key has been compromised.

<div className={cx(docsStyles.centered, streamsStyles.streamApiAccess)}>
  <img src={StreamApiAccess} />
</div>

#### Historical Data section
This section contains the stream's historical data storage settings and includes tools to add or remove historical data from the stream. 

<div className={cx(docsStyles.centered, streamsStyles.streamHistorical)}>
  <img src={StreamHistorical} />
</div>

You can add new data to the stream by uploading a CSV file and you can delete existing historical data from the stream by choosing an inclusive date range. 

The historical data storage period determines how many days your data is retained before it will be removed automatically from the Streamr network. The default period is 365 days.

</section>
<section id="work-with-streams-via-sdks">

## Work with streams via SDKs

The easiest way to work with streams is to use the JavaScript client, which works in **Node.js** as well as the browser. See the <Link to={links.newdocs.SDKs}>SDKs section</Link> for the official and community-maintained client libraries available for various languages.

### Authentication

When reading from or writing to streams, you need to provide a session token or an API key, or login with an Ethereum account. To read more about API keys or obtaining a session token, refer to the <Link to={`${links.newdocs.api}#authentication`}>Authentication section of the API docs</Link>.

### Creating a client instance with API key

**Javascript**

<CodeSnippet language='javascript'>{CreateJavascriptClient}</CodeSnippet>

**Java**

<CodeSnippet language='java'>{CreateJavaClient}</CodeSnippet>

### Subscribing to realtime events in a stream

By subscribing to Streams, your application gets immediately notified about new events in the stream.

**JavaScript**

<CodeSnippet language='javascript'>{SubscribeJavascriptClient}</CodeSnippet>

**Java**

<CodeSnippet language='java'>{SubscribeJavaClient}</CodeSnippet>

### Publishing events to Streams

**JavaScript**

<CodeSnippet language='javascript'>{PublishJavascriptClient}</CodeSnippet>

**Java**

Events in Streams are key-value pairs, represented in Java as Map objects. Below is an example of creating an event payload and publishing it into a Stream:

<CodeSnippet language='java'>{PublishJavaClient}</CodeSnippet>

</section>
<section id="work-with-streams-via-api">

## Work with streams via API

While the Core UI can do just about everything you'd want to do with streams, sometimes the using the API directly is preferred.

### Data output over HTTP

Events in streams can be queried via HTTP. Example using `curl`:

<CodeSnippet language='bash'>
    {`curl -i -X POST -H "Authorization: Bearer MY-SESSION-TOKEN" -d "{\"foo\":\"hello\",\"bar\":24.5}" https://www.streamr.com/api/v1/streams/MY-STREAM-ID/data`}
</CodeSnippet>

The following endpoint would return the 5 most recent messages in a stream (or to be more precise, the default partition 0 of a stream):

<CodeSnippet language='json'>{`https://www.streamr.com/api/v1/streams/{id}/data/partitions/0/last?count=5`}</CodeSnippet>

The HTTP API covers session management, data input, data output, and managing Streamr resources such as Canvases, Streams, and Dashboards. The endpoints allow you to list, create, read, update and delete the resources, as well as execute resource-specific actions such as start and stop Canvases.

You best way to view all of streams endpoints is in the <a href="https://api-explorer.streamr.com" target="_blank">API explorer</a>.

</section>
<section id="data-signing-and-verification">

## Data signing and verification

Authenticity and integrity of events published on a stream can be guaranteed with digital signatures. Every stream's metadata has a boolean `requiresSignedData` that can be set by the stream's owner to let subscribers know whether they should expect signed or unsigned events.

Every message published to a stream has six fields that uniquely identify this message across time, all streams and all publishers:

- `streamId`
- `streamPartititon`
- `timestamp`
- `sequenceNumber`
- `publisherId`
- `msgChainId`

More details about these fields can be found in the <a href="https://github.com/streamr-dev/streamr-specs" target="_blank">protocol specification</a>. All together they form the message ID. They must be signed along with the actual message `content` to resist against replay attacks.

So the payload to be signed for every message by every publisher is the following:

```
payload = streamId + streamPartition + timestamp + sequenceNumber + publisherId + msgChaindId + content
```

The signing algorithm follows the convention described <a href="https://github.com/ethereum/EIPs/blob/master/EIPS/eip-712.md" target="_blank">here</a>. The secp256k1 ECDSA algorithm is applied on the keccak256 hash of a string derived from the challenge text:

```
signature = sign(keccak256("\x19Ethereum Signed Message:\\n" + len(payload) + payload)))
```

On the recipient side, every subscriber needs to verify signed events. If a received event is unsigned, the subscriber accepts the event if and only if the stream's boolean flag `requiresSignedData` is set to `false`.

The signature verification is done in three steps:

1. the subscriber extracts from the event and the signature the Ethereum address that signed the message (using the EC recover operation).
2. Check that the address recovered in step 1 matches the address defined by `publisherId`
3. Check that this `publisherId` belongs to the set of valid publishers for that stream by querying the `api/v1/streams/${id}/publishers` endpoint.

Both signature computation and verification are implemented in the Javascript and Java SDKs.

</section>
<section id="end-to-end-encryption">

## End-to-end encryption
***Documentation coming soon***

</section>
<section id="partitioning">

## Partitioning

To be precise, when messages are published to a stream, they are actually published to a **partition** within that stream. Partitions can be understood as sub-streams, or in other words, parts of a stream. One partition per stream is the default, which is sufficient for streams with moderate rates of data (approx. less than 100 msg/sec).

When a stream needs to handle large data rates, partitions are used for *sharding* of the data. Sharding data simply means dividing a large volume of messages to multiple partitions, a bit like a large river can split the same amount of water to multiple smaller branches. Each partition shares the general properties of the parent stream, such as name, description, and user permissions, but the partitions behave independently when it comes to delivering and storing data in the Streamr Network, which allows for scalability.

<img src={StreamAndPartitionsImage} />

Partitions also enable subscribers to scale horizontally: a user consuming data from a stream could load balance the messages over a number of consuming processes, up to the number of partitions. So if a stream has 5 partitions, the user could start up to 5 independent subscribers on separate physical machines, with each subscriber receiving different messages (each process subscribes to a unique partition).

Partitions are identified by a number which starts from zero. For example, a stream with only one partition contains the partition `0` and all of the stream's data flows through this partition. A stream with 5 partitions has partitions `0` through `4` - here the stream's data is distributed across these 5 partitions. The data publisher is free to choose the target partition for each message. If no partition is specified, the data goes to partition 0.

While the data publisher is free to choose a target partition for a message arbitrarily, a common approach is to utilize a *partition key*. A partition key is a value chosen from the data which is used to determine the partition of the message. For example, a customer ID could be used as a partition key in an application that publishes customer interactions to a stream. This way, all messages from a particular customer always go to the same partition. This is useful because it keeps all the events related to a particular customer in a single and known partition instead of spreading them over all partitions.

<img src={MessagePartitioningImage} />

The `publish` methods in the <Link to={links.newdocs.SDKs}>Streamr SDKs</Link> usually take an optional `partitionKey` parameter. For example, in the JS client:

```
streamr.publish(stream, message, timestamp, partitionKey)
```

Internally, the library maps the `partitionKey` to a partition number using a hash function (modulo the number of partitions in the stream):

```
partition = hash(partitionKey) % numberOfPartitions
```

<Warning>

At the time of writing, there are some limitations with multi-partition streams: The number of partitions can only be set when creating streams via the API, and the number cannot be changed afterwards. When using multi-partition streams on canvases, the canvases always subscribe to all partitions in a stream.

</Warning>

Currently partitions don’t have well-defined rate limits, but future versions of the P2P network may enforce limits. For now, we recommend not exceeding around 100 msg/sec/partition.

</section>
